---
title: "Analyzing Storm Data"
author: "Egor Ignatenkov"
date: "Thursday, September 18, 2014"
output: html_document
---

First, let's get our file and read some data.

```{r download, cache=TRUE}
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2", "stormdata.bz2")
data_header<-read.csv("stormdata.bz2", header = FALSE, nrow = 1)
take<-c("BGN_DATE", "BGN_TIME", "STATE", "EVTYPE", "FATALITIES", "INJURIES", "PROPDMG", "CROPDMG")
takecols <- ifelse(t(data_header) %in% take, NA, 'NULL')
data<-read.csv("stormdata.bz2", colClasses=takecols)
```

Let's see what we've got:

```{r}
head(data, n = 10)
```

Now, let's try to answer this question:

####Across the United States, which types of events are most harmful with respect to population health?

We will have to look to the "EVTYPE" column. The data in that column is not very neat: there are some entries that differ only by uppercase/lowercase (WIND/Wind) or plural/singular form (WILDFIRE/WILDFIRES), so we'll have to do some cleaning. 

First, we get rid from rows with 0 injuries (for our purposes there's no point in dealing with WIND/Wind problems if there's no injuries stated in "Wind" entries; it's easier just to remove all such rows)

```{r cleanzeros, cache=TRUE}
data_new<-data.frame()
for (i in seq(1:nrow(data))){
if (data[i,6]!=0 ) {
data_new<-rbind(data_new, data[i,])
}
}
```

Now we sum number of injuries by event type.

```{r, cache=TRUE}
pop_health<-aggregate(INJURIES ~ EVTYPE, data = data_new, sum)
```

Let's check how many entries we have:
```{r}
nrow(pop_health)
```

Let's look on what's on top.

```{r}
head(pop_health[order(-pop_health$INJURIES),],20)
```

It's clear now that it's no point in dealing with typos, because tornadoes will obviously keep the first place (no more than 140 entries after top-20, each no more than 440, so total number of injuries under top-20 is less than 61600 and even if all of them are some typos of TSTM WIND they add up to less than 70000 which is less than 91346 injuries from tornadoes).