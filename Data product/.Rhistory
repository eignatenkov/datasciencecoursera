inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ind
preProc<-preProcess(training[,ind],method="pca",thresh=0.9)
preProc$numComp
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
summary(training)
dim(training)
plot(training$diagnosis)
qplot(training$diagnosis)
dim(training)
dim(testing)
summary(training$diagnosis)
summary(testing$diagnosis)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
summary(training$diagnosis)
summary(testing$diagnosis)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
summary(testing$diagnosis)
diagnosis
predictors
dim(adData)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
set.Seed(125)
?seed
?setSeed
set.seed(125)
head(testing)
colnames(testing)
fit<-train(Case~.,method="rpart",data=training)
summary(fit)
predict(fit,TotalIntench2 = 23000; FiberWidthCh1 = 10; PerimStatusCh1=2 )
predict(fit,TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2 )
predict(fit,newdata=testing)
table(testing$Case)
table(training$Case)
table(segmentationOriginal$Case)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
table(training$Case)
summary(training)
fit<-train(Class~.,method="rpart",data=training)
confusionMatrix(testing$Class,predict(fit,newdata=testing))
confusionMatrix(training$Class,predict(fit,newdata=training))
test<-data.table()
test<-data.frame()
colnames(test)<-c("TotalIntench2","FiberWidthCh1","PerimStatusCh1","VarIntenCh4")
ncol(test=4)
ncol(test)=4
test<-data.frame(ncol=4,nrow=4)
colnames(test)<-c("TotalIntench2","FiberWidthCh1","PerimStatusCh1","VarIntenCh4")
?data.frame
test
test<-data.frame(ncols=4,nrows=4,NA)
test
test<-as.data.frame(setNames(c("TotalIntench2","FiberWidthCh1","PerimStatusCh1","VarIntenCh4"))
)
a<-c(23000,10,2,0)
a
b<-c(50000,10,0,100)
c<-c(57000,8,0,100)
d<-c(0,8,2,100)
test<-data.frame(a,b,c,d)
test
test<-data.frame(a;b;c;d)
a
colnames(a)<-c("TotalIntench2","FiberWidthCh1","PerimStatusCh1","VarIntenCh4")
test<-test''
test <- as.data.frame(setNames(replicate(4,numeric(0), simplify = F), letters[1:4]))
test
test[1,]<-c(23000,10,2,0)
test
test[2,]<-c(50000,10,0,100)
test[3,]<-c(57000,8,0,100)
test[4,]<-c(0,8,2,100)
colnames(test)<-c("TotalIntench2","FiberWidthCh1","PerimStatusCh1","VarIntenCh4")
test
predict(fit,newdata=test)
predict(fit,newdata=testing)
predict(fit,newdata=testing[testing$TotalIntench2==23000,])
testing[testing$TotalIntench2<24000,]
testing
testing[testing$TotalIntenCh2<24000,]
testing[testing$TotalIntenCh2=24000,]
testing[testing$TotalIntenCh2==24000,]
testing[testing$TotalIntenCh2==57000,]
plot(fit)
fit<-train(Class~.,method="rpart",data=training)
print(fit$finalModel)
plot(fit$finalModel)
plot(fit$finalModel, uniform=TRUE,
main="Classification Tree")
text(fit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
fit<-train(Area~.,method='rpart',data=olive)
print(fit$finalModel)
plot(fit$finalModel)
text(fit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
newdata = as.data.frame(t(colMeans(olive)))
newdata
predict(fit,newdata=newdata)
head(olive)
summary(olive)
olive$Area<-as.factor(olive$Area)
summary(olive)
fit<-train(Area~.,method='rpart',data=olive)
print(fit$finalModel)
predict(fit,newdata=newdata)
tree(fit,newdata=newdata)
?tree
install.packages(tree)
install.packages('tree')
?tree
?tree()
tree(fit,newdata=newdata)
library(tree)
?tree
fit<-tree(Area~.,data=olive)
predict(fit,newdata=newdata)
print(fit$finalModel)
plot(fit)
text(fit)
newdata
predict(fit,newdata=olive)
newdata
predict(fit,newdata=newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages('ElemStatLearn')
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
colnames(SAheart)
fit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method='glm',family="binomial",data=SAheart)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
fit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method='glm',family="binomial",data=trainSA)
missClass(testSA$chd,predict(fit,newdata=testSA))
missClass(trainSA$chd,predict(fit,newdata=trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
summary(vowel.train)
set.seed(33833)
fit<-train(y~.,method="rf",data=vowel.train)
fit<-train(y~.,method="rf",data=vowel.train)
confusionMatrix(vowel.test$y,predict(fit,newdata=vowel.test$y))
confusionMatrix(vowel.test$y,predict(fit,newdata=vowel.test))
?varImp
varImp.randomForest(fit)
varImp(fit)
fit<-train(y~.,method="rf",data=vowel.train,importance=TRUE)
varImp(fit,type=2)
fit<-randomForest(y~.,method="rf",data=vowel.train)
importance(fit)
order(importance(fit))
set.seed(33833)
fit<-randomForest(y~.,method="rf",data=vowel.train)
order(importance(fit))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
fit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method='glm',family="binomial",data=trainSA)
missClass(testSA$chd,predict(fit,newdata=testSA))
missClass(trainSA$chd,predict(fit,newdata=trainSA))
newdata
fit<-tree(Area~.,data=olive)
predict(fit,newdata=newdata)
newdata = as.data.frame(t(colMeans(olive)))
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
fit<-tree(Area~.,data=olive)
predict(fit,newdata=newdata)
getwd()
training<-read.csv('training.csv')
testing<-read.csv('testing.csv')
training<-training[,-c(6,12:36,50:59,69:83,87:101,103:112,125:150)]
testing<-testing[,-c(6,12:36,50:59,69:83,87:101,103:112,125:150)]
training<-training[,-c(1,3:6)]
testing<-testing[,-c(1,3:6)]
library(caret)
library(randomForest)
fit<-randomForest(classe~.,data=training,na.action=na.omit)
library(caret)
library(randomForest)
fit<-randomForest(classe~.,data=training)
confusionMatrix(training$classe,predict(fit,newdata=training))
answers<-predict(fit,newdata=testing)
answers
library(tree)
fit2<-tree(classe~.,data=training)
predict(fit2,newdata=testing)
print(fit)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
install.packages('gbm')
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fit1<-train(diagnosis~.,method="rf",data=training)
fit2<-train(diagnosis~.,method="gbm",data=training,verbose=TRUE)
fit2<-train(diagnosis~.,method="gbm",data=training,verbose=FALSE)
fit3<-train(diagnosis~.,method="lda",data=training)
confusionMatrix(predict(fit1,newdata=testing),testing$diagnosis)
confusionMatrix(predict(fit2,newdata=testing),testing$diagnosis)
confusionMatrix(predict(fit3,newdata=testing),testing$diagnosis)
confusionMatrix(predict(fit3,newdata=training),training$diagnosis)
confusionMatrix(predict(fit2,newdata=training),training$diagnosis)
confusionMatrix(predict(fit1,newdata=training),training$diagnosis)
predict(fit1,newdata=training)
training$diagnos
training$diagnosis
adData
adData$diagnosis
inTrain
training = adData[ inTrain,]
training
training$diagnosis
pred1<-predict(fit1,newdata=testing)
pred1
testing$diagnosis
pred2<-predict(fit2,newdata=testing)
pred3<-predict(fit3,newdata=testing)
df<-data.frame(pred1,pred2,pred3,testing$diagnosis)
comb<-train(df$testing.diagnosis~.,method="rf",data=df)
confusionMatrix(predict(comb,newdata=testing),newdata=df)
confusionMatrix(predict(comb,newdata=df),testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
fit<-train(CompressiveStrength~.,method="lasso",data=training)
fit<-train(CompressiveStrength~.,method="lasso",data=training)
?plot.enet
plot(fit)
plot.enet(fit)
?enet
m_train<-enet(training[,1:8],training[,9],lambda=0)
m_train<-as.matrix(training)
lasso<-enet(m_train[,1:8],m_train[,9],lambda=0)
plot(lasso)
enet.plot(lasso)
plot.enet(lasso)
predict(lasso,newdata=testing)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",method="wget",'q4q4.csv')
install.packages('lubridate')
library(lubridate)  # For year() function below
dat = read.csv("q4q4.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages('forecast')
library(forecast)
?bats
fit<-bats(training)
head(training)
fit<-bats(visitsTumblr~date,data=training)
head(tstrain)
fit<-bats(tstrain)
fcast<-forecast(fit)
fcast
accuracy(fcast,testing)
accuracy(fcast,ts(testing$visitsTumblr))
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
install.packages('quantmod')
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
getSymbols("GOOG", src="google", from = from.dat, to = to.dat, auto.assign = TRUE)
head(GOOG)
getSymbols("GOOG", src="google", from = from.dat, to = to.dat, auto.assign = FALSE)
?forecast
fcast
training
fcast(367)
head(fcast)
tstrain
testing
plot(fcast)
plot(fcast)
fcast
?forecast
str(testing)
fcast<-forecast(fit,h=235,level=.95)
plot(fcast)
fcast
fcast<-forecast(fit,h=235,level=.975)
fcast
testing
testing$visitsTumblr<fcast$lower
((testing$visitsTumblr<fcast$lower)&(testing$visitsTumblr>fcast$higher))*1
(testing$visitsTumblr<fcast$lower)&(testing$visitsTumblr>fcast$higher)
(testing$visitsTumblr<fcast$lower)&&(testing$visitsTumblr>fcast$higher)
2>3
2>1
2>1&2>3
fcast$lower
fcast$higher
fcast$upper
(testing$visitsTumblr<fcast$lower)&&(testing$visitsTumblr>fcast$upper)
(testing$visitsTumblr<fcast$lower)&(testing$visitsTumblr>fcast$upper)
(testing$visitsTumblr<fcast$lower)&(testing$visitsTumblr>fcast$upper)*1
((testing$visitsTumblr<fcast$lower)&(testing$visitsTumblr>fcast$upper))*1
sum(((testing$visitsTumblr<fcast$lower)&(testing$visitsTumblr>fcast$upper))*1)
sum(((testing$visitsTumblr<fcast$lower)|(testing$visitsTumblr>fcast$upper))*1)
testing$visitsTumblr
fcast$lower
fcast<-forecast(fit,h=235,level=.025)
fcast
fcast<-forecast(fit,h=235,level=97.5)
fcast
sum(((testing$visitsTumblr<fcast$lower)|(testing$visitsTumblr>fcast$upper))*1)
str(testing)
7/235
235-7/235*100
(235-7/235)*100
(235-7)/235*100
fcast<-forecast(fit,h=235,level=95)
sum(((testing$visitsTumblr<fcast$lower)|(testing$visitsTumblr>fcast$upper))*1)
(235-9)/235*100
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
install.packages('e1071')
str(training)
fit<-train(CompressiveStrength~.,method="svm",data=training)
fit<-svm(CompressiveStrength~.,data=training)
library(e1071)
fit<-svm(CompressiveStrength~.,data=training)
ptest<-predict(fit,newdata=testing)
confusionMatrix(ptest,testing$CompressiveStrength)
ptest
testing$CompressiveStrength
str(pTest)
str(ptest)
ptest<-as.numeric(ptest)
confusionMatrix(ptest,testing$CompressiveStrength)
str(testing$CompressiveStrength)
str(ptest)
fit
sqrt(sum((ptest-testing$CompressiveStrength)^2))
set.seed(325)
fit<-svm(CompressiveStrength~.,data=training)
ptest<-predict(fit,newdata=testing)
sqrt(sum((ptest-testing$CompressiveStrength)^2))
sqrt(sum((ptest-testing$CompressiveStrength)^2)/length(ptest))
version()
install.packages(c("BH", "caret", "CORElearn", "digest", "httr", "jsonlite", "lazyeval", "magrittr", "manipulate", "RColorBrewer", "RcppArmadillo", "RcppEigen", "RCurl", "reshape2", "swirl"))
install.packages(c("BH", "caret", "CORElearn", "digest", "httr",
install.packages(c("BH", "caret", "CORElearn", "digest", "httr", "jsonlite", "lazyeval", "magrittr", "manipulate", "RColorBrewer", "RcppArmadillo", "RcppEigen", "RCurl", "reshape2", "swirl"))
install.packages(c("BH", "caret", "CORElearn", "digest", "httr", "jsonlite", "lazyeval", "magrittr", "manipulate", "RColorBrewer", "RcppArmadillo", "RcppEigen", "RCurl", "reshape2", "swirl"))
install.packages(c("BH", "caret", "CORElearn", "digest", "httr",
"jsonlite", "lazyeval", "magrittr", "manipulate", "RColorBrewer", "RcppArmadillo", "RcppEigen", "RCurl", "reshape2", "swirl"))
diabetesRisk <- function(glucose) glucose/200
diabetesRisk(500)
install.packages('shiny')
library(shiny)
runExample("01_Hello")
runExample("01_hello")
getwd()
setwd("/home/egor/datasciencecoursera/Data product/")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages('UsingR')
runApp()
library(devtools)
install.packages('devtools')
install_github("ramnathv/rCharts@dev")
library(devtools)
install_github("ramnathv/rCharts@dev")
install.packages('base64enc')
install_github("ramnathv/rCharts@dev")
runApp()
runApp()
x<-1
runApp()
runApp(display.mode='showcase')
runApp(display.mode='showcase')
runApp(display.mode='showcase')
require(rCharts)
haireye = as.data.frame(HairEyeColor)
n1 <- nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart',
data = subset(haireye, Sex == 'Male')
)
n1$save('fig/n1.html', cdn = TRUE)
cat('<iframe src="fig/n1.html" width=100%, height=600></iframe>')
n1
n1$save('n1.html',cdn=TRUE)
cat('<iframe src="n1.html" width=100%, height=600></iframe>')
n1
n1$html
## Example 1 Facetted Scatterplot
names(iris) = gsub("\\.", "", names(iris))
r1 <- rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
r1
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'bar')
r1<-rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'bar')
r1
r1$save('r1.html')
r1<-rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
r1
r1$save('r1.html')
r2<-rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'bar')
r2$save('r2.html',cdn=TRUE)
r2$publish('myPlot', host = 'rpubs')
data(economics, package = "ggplot2")
econ <- transform(economics, date = as.character(date))
m1 <- mPlot(x = "date", y = c("psavert", "uempmed"), type = "Line", data = econ)
m1$set(pointSize = 0, lineWidth = 1)
m1$save('m1.html', cdn = TRUE)
require(reshape2)
uspexp <- melt(USPersonalExpenditure)
names(uspexp)[1:2] = c("category", "year")
x1 <- xPlot(value ~ year, group = "category", data = uspexp, type = "line-dotted")
x1$save('x1.html', cdn = TRUE)
cat('<iframe src="fig/x1.html" width=100%, height=600></iframe>')
hair_eye = as.data.frame(HairEyeColor)
r2 <- rPlot(Freq ~ Hair | Eye, color = 'Eye', data = hair_eye, type = 'bar')
r2$save('r2.html', cdn = TRUE)
cat('<iframe src="fig/r2.html" width=100%, height=600></iframe>')
r2
suppressPackageStartupMessages(library(googleVis))
install.packages('googleVis')
suppressPackageStartupMessages(library(googleVis))
M <- gvisMotionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
print(M, "chart")
M <- gvisMotionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
M
print(M)
print(M,'chart')
M$save(m.html, cdn = TRUE)
M
G <- gvisGeoChart(Exports, "Country", "Profit",options=list(width=200, height=100))
print(G,'chart')
print(G,"chart")
demo(googleVis)
plot(M,"chart")
